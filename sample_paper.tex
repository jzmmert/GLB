\documentclass[twoside]{article} \usepackage{aistats2017}

% If your paper is accepted, change the options for the package
% aistats2017 as follows:
%
%\usepackage[accepted]{aistats2017}
%
% This option will print headings for the title of your paper and
% headings for the authors names, plus a copyright note at the end of
% the first column of the first page.

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{color}
\usepackage{amsthm}

\newcommand{\Reg} {
  \operatorname{Reg}}
\begin{document}

% If your paper is accepted and the title of your paper is very long,
% the style will print as headings an error message. Use the following
% command to supply a shorter title of your paper so that it can be
% used as headings.
%
%\runningtitle{I use this title instead because the last one was very long}

% If your paper is accepted and the number of authors is large, the
% style will print as headings an error message. Use the following
% command to supply a shorter version of the authors names so that
% they can be used as headings (for example, use only the surnames)
%
%\runningauthor{Surname 1, Surname 2, Surname 3, ...., Surname n}

\twocolumn[

\aistatstitle{Generalized Linear Bandits revisited}

\aistatsauthor{ Julian Zimmert \And Csaba Szepesvári  }

\aistatsaddress{ Humboldt University of Berlin \And University of Alberta  } ]

\begin{abstract}
Previous work on generalized linear bandits (GLB) suggested that algorithms based on optimism 
can achieve a $\sqrt{T}$-regret analogous to the linear bandit setting. We argue however, 
that these results should be treated as asymptotic results, as they include generally huge constants 
that might even be a priori unknown. Our novel lower bound for GLB proves that these constants are not
mere artifacts of the analysis, but that the regret might be as large as $\Omega(\frac{1}{2}+\frac{d-1}{2d+6})$.
We prove that this lower bound has a matching upper bound up to log factors on a finite time setting with unit ball arms.
\end{abstract}

\section{Introduction}

We are concerned about the problem of general linear bandits (GLB) which are an extension of linear bandits that generalize the classical K-armed bandit problem.
In the K-armed bandit problem, an agent selects one out of K possible arms at each time and immediately observes a reward.
The reward depends only on the selected arm and is assumed to be drawn out of a probability distribution. 
The means of the distributions are unknown and independent of each other, but the tails are all assumed to be sub-Gaussian.
In these problems, the agent is faced with a fundamental trade-off between playing arms to gain information about the reward structure (Exploration) and chooses the arm that is most promising given the available information (Exploitation).
For linear bandits, we model an an underlying structure that links the mean rewards for different arms. 
In this setting, each arm is attached to a $d$-dimensional feature vector $x$ and the mean reward is given by $x^T\theta_*$, for an unknown parametrization $\theta_*$.
Because this allows to infer information about arms that were never played, meaningful results exist even for infinitely many arms.
GLB also assumes a feature structure, but the mean reward is $\mu(x^T\theta_*)$ for a non-decreasing link function $\mu$.

For both the K-armed bandit as well as the linear bandit problems, algorithms with favourable theoretical properties exist. The regret, that is the accumulated difference of rewards between playing the optimal arm at each time-step and following the algorithm, is bounded by $\tilde{\mathcal{O}}(\sqrt{T})$ with high probability. 
Existing proofs for lower bounds show that improvement is impossible for all except constants and log factors.
An analogous algorithm for GLB also guarantees $\tilde{\mathcal{O}}(\sqrt{T})$ regret, but we see two downsides of this result. First of all, it needs to assume that the derivative of $\mu$ is lower bounded away from $0$. $\dot{\mu}\geq c_\mu > 0$. 
Secondly, the bound requires two constants that might get extremely large, making this result more asymptotic in nature. 
We are showing in this work that these constants are not mere artifacts of the analysis.
Worst still, we show that the $T$ dependency is greater than $\sqrt{T}$ once we do not lower bound $\dot{\mu}$.
Additionally we are going to prove that the estimator of $\theta_*$ ,used in the work of \cite{}, is fundamentally sub-optimal.


\section{Problem setting and existing results}
The agent plays for a total of $T$ rounds and chooses an arm $X_t$ at each round. 
We assume that the arms come from a closed subset $S$ of the $d$-dimensional euclidean space $x_i \in S\subset\mathbb{R}^d$, are bounded in length by L and that the features are known to the agent.
There exists a bounded unknown parameter $\theta_*\in \mathbb{R}$, $||\theta_*||_2 \leq R$.
When the agent plays an arm $x_i$ at time $t$, he will observe the reward $R_t = \mu(x_i^T\theta_*) +\eta_t$. $\mu$ is hereby a non-decreasing link function that is $k_\mu$-Lipschitz and $\eta_t$ is a random noise that is $\lambda$-subgaussian. The optimal arm is denoted $x_*$: $\max_x\mu(x^T\theta_*) = \mu(x_*^T\theta_*)$. For a given strategy, we denote with $x_t$ the arm that is chosen at time $t$.\\
The immediate regret at time $t$ is defined as 
$$\Reg_t := \mathbb{E}\left[R_t|X_t=x_*\right]-\mathbb{E}\left[R_t|X_t=x_t\right]$$,
and the total regret or simply regret is the cumulative sum of immediate regrets
$$\Reg(T) := \sum_{i=1}^T \Reg_i.$$
We define two different estimators in this section.
The second is used in the work of \ref{}, the other, we believe, is more favorable in this setting.
Given observations $(R_1,X_1), (R_2,X_2),\ldots,(R_{t-1},X_{t-1})$, the least square estimator (LSE) $\hat{\theta}$ is defined as the minimizer of
$$\sum_{k=1}^{t-1}\left(R_k - \mu(X_k^T\theta_*)\right)^2.$$
Consistency of the LSE in our setting is a standard result \ref{}.

The pseudo maximum likelihood estimator (pseudo-MLE), is defined as the solution $\hat{\theta}_P$ of the equation
$$\sum_{k=1}^{t-1}(R_k-\mu(X_k^T\hat{\theta}_P))X_k = 0.$$
The estimator is consistent under very general assumptions, however it requires again that $\dot{\mu}$ is bounded away from zero, which is why this estimator is unfavourable in our setting.
For self consistency, we briefly explain the rationale behind this estimator.
If the rewards are actually drawn from a \textit{canonical exponential family}, that means the density for a reference measure is
$$p_\beta(r) = \exp(r\beta − b(\beta) + c(r)) ,$$
then the pseudo-MLE is simply the regular maximum likelihood estimator. $\beta$ is a real number, $c$ is a real-valued function and $b$ is twice continuously differentiable. The mean is given by $\mathbb{R}[R] = \dot{b}(\beta)$ ( $=\mu(\beta)$ ) and the tails are indeed subgaussian. 

An algorithm based on the \textit{optimism in the face of uncertainty} principles is proven to satisfy a bound on the regret of the shape $\tilde{\mathcal{O}}(\frac{k\mu}{c_\mu}\sqrt{T})$. 
The motivating function for this setting is traditionally the sigmoid function $f(x) = (1+\exp(-x))^{-1}$.
W.l.o.g. we can reformulate the problem such that $||x||,||\theta_*||\leq 1$ and $\mu:[-1,1]\rightarrow\mathbb{R}$,
$\mu(x) = (1+\exp(-LR_{\max}x))^{-1}$.
In this case $k_\mu = \frac{LR}{4}$, $c_\mu^{-1} = \left(\frac{LR}{(e^{0.5LR}+e^{-0.5LR})^2}\right)^{-1} > \frac{\exp(LR)}{LR}$. The constant in front of $T$ grows exponentially with the possible length of $\theta_*$ and the arms, rendering this bound meaningless for most applications.


\section{Lower bounds} \label{lowerBounds}

We now present the main result of the paper. The general lower bound proves the claim that the constants are not mere artifacts of the analysis, while the algorithm dependent bound proofs that there is an insuperable gap when using the pseudo MLE for subgaussian noise.

\subsection{Algorithm independent bound}

The exponent $\frac{}{}$ converges to $1$ as the dimension increases, that means for a finite time horizon and large dimensions, the regret will almost be undistinguishable from linear regret. 
In real world application, we typically deal with relatively large dimensions. 
Unless we are very careful about the chosen link function, it might be impossible to learn anything meaningfull in a given time.
That is why we distinguish in \ref{upperBounds} between different families of link functions, to provide safe-to-use applications.

\subsection{Pseudo Maximum-Likelihood based lower bound}
For simplicity, we assume a simple Explore then Commit algorithm. 
We show that for any time horizon $T$, we can construct a problem where with constant probability the pseudo MLE choses an arm not better than random.
During the exploration, we suffer an regret even larger than what the general lower bound predicts.

\section{Upper bounds}\label{upperBounds}
The lower bound given in the previous section is of a relatively odd nature. 
To our best knowledge, the hasn't been a similar exponent derived for any bandit related lower bound.
This naturally raises the question, whether this is even a tight lower bound.
While for practical purposes, this is of little relevance because it is already prohibitive with the existing bound, it is still of academic interest.
Secondly, it is essential for provide well behaving function that are guaranteed to suffer $\sqrt{T}$ regret instead.

We are not yet able to provide a complete answer to these question. 
Based on a slightly simplified setting, we can show that
\begin{itemize}
\item the lower bound is indeed tight up to log factors
\item symmetric convex-concave link functions are safe-to-use
\end{itemize}

\paragraph{Restrictions}
We believe the results hold even without further restrictions, but removing them would complicate the proofs to a point that would burst all limits of our appendix.
In this section, we assume that
\begin{itemize}
\item the arms consists of the $d$-dimensional unit ball
\item $||\theta_*||$ is known.
\item The derivative $\dot{\mu}$ is axis symmetric and monotonous
\end{itemize}
\subsection{concave-convex link functions}
We will first 
\subsection{convex-concave link functions}

\subsubsection{Citations in Text}

Citations within the text should include the author's last name and
year, e.g., (Cheesman, 1985). References should follow any style that
you are used to using, as long as their style is consistent throughout
the paper.  Be sure that the sentence reads correctly if the citation
is deleted: e.g., instead of ``As described by (Cheesman, 1985), we
first frobulate the widgets,'' write ``As described by Cheesman
(1985), we first frobulate the widgets.''  Be sure to avoid
accidentally disclosing author identities through citations.

\subsubsection{Footnotes}

Indicate footnotes with a number\footnote{Sample of the first
  footnote.} in the text. Use 8 point type for footnotes. Place the
footnotes at the bottom of the column in which their markers appear,
continuing to the next column if required. Precede the footnote
section of a column with a 0.5 point horizontal rule 1~inch (6~picas)
long.\footnote{Sample of the second footnote.}

\subsubsection{Figures}

All artwork must be centered, neat, clean, and legible.  All lines
should be very dark for purposes of reproduction, and art work should
not be hand-drawn.  Figures may appear at the top of a column, at the
top of a page spanning multiple columns, inline within a column, or
with text wrapped around them, but the figure number and caption
always appear immediately below the figure.  Leave 2 line spaces
between the figure and the caption. The figure caption is initial caps
and each figure should be numbered consecutively.

Make sure that the figure caption does not get separated from the
figure. Leave extra white space at the bottom of the page rather than
splitting the figure and figure caption.
\begin{figure}[h]
\vspace{.3in}
\centerline{\fbox{This figure intentionally left non-blank}}
\vspace{.3in}
\caption{Sample Figure Caption}
\end{figure}

\subsubsection{Tables}

All tables must be centered, neat, clean, and legible. Do not use hand-drawn tables. Table number and title always appear above the table.
See Table~\ref{sample-table}.

Use one line space before the table title, one line space after the table title, and one line space after the table. The table title must be
initial caps and each table numbered consecutively.

\begin{table}[h]
\caption{Sample Table Title} \label{sample-table}
\begin{center}
\begin{tabular}{ll}
{\bf PART}  &{\bf DESCRIPTION} \\
\hline \\
Dendrite         &Input terminal \\
Axon             &Output terminal \\
Soma             &Cell body (contains cell nucleus) \\
\end{tabular}
\end{center}
\end{table}

\section{SUPPLEMENTARY MATERIAL}

If you need to include additional appendices during submission, you
can include them in the supplementary material file.


\newpage

\section{INSTRUCTIONS FOR CAMERA-READY PAPERS}

For the camera-ready paper, if you are using \LaTeX, please make sure
that you follow these instructions.  (If you are not using \LaTeX,
please make sure to achieve the same effect using your chosen
typesetting package.)

\begin{enumerate}
    \item Download \texttt{fancyhdr.sty} -- the
    \texttt{aistats2017.sty} file will make use of it.
    \item Begin your document with
    \begin{flushleft}
    \texttt{\textbackslash documentclass[twoside]\{article\}}\\
    \texttt{\textbackslash usepackage[accepted]\{aistats2017\}}
    \end{flushleft}
    The \texttt{twoside} option for the class article allows the
    package \texttt{fancyhdr.sty} to include headings for even and odd
    numbered pages. The option \texttt{accepted} for the package
    \texttt{aistats2017.sty} will write a copyright notice at the end of
    the first column of the first page. This option will also print
    headings for the paper.  For the \emph{even} pages, the title of
    the paper will be used as heading and for \emph{odd} pages the
    author names will be used as heading.  If the title of the paper
    is too long or the number of authors is too large, the style will
    print a warning message as heading. If this happens additional
    commands can be used to place as headings shorter versions of the
    title and the author names. This is explained in the next point.
    \item  If you get warning messages as described above, then
    immediately after $\texttt{\textbackslash
    begin\{document\}}$, write
    \begin{flushleft}
    \texttt{\textbackslash runningtitle\{Provide here an alternative shorter version of the title of your
    paper\}}\\
    \texttt{\textbackslash runningauthor\{Provide here the surnames of the authors of your paper, all separated by
    commas\}}
    \end{flushleft}
    Note that the text that appears as argument in \texttt{\textbackslash
      runningtitle} will be printed as a heading in the \emph{even}
    pages. The text that appears as argument in \texttt{\textbackslash
      runningauthor} will be printed as a heading in the \emph{odd}
    pages.  If even the author surnames do not fit, it is acceptable
    to give a subset of author names followed by ``et al.''

    \item Use the file sample\_paper.tex as an example.

    \item Both submitted and camera-ready versions of the paper are 8
      pages, plus any additional pages needed for references.

    \item If you need to include additional appendices,
      you can include them in the supplementary
      material file.

    \item Please, don't change the layout given by the above
      instructions and by the style file.

\end{enumerate}

\subsubsection*{Acknowledgements}

Use unnumbered third level headings for the acknowledgements.  All
acknowledgements go at the end of the paper.  Be sure to omit any
identifying information in the initial double-blind submission!


\subsubsection*{References}

References follow the acknowledgements.  Use an unnumbered third level
heading for the references section.  Any choice of citation style is
acceptable as long as you are consistent.  Please use the same font
size for references as for the body of the paper---remember that
references do not count against your page length total.

J.~Alspector, B.~Gupta, and R.~B.~Allen (1989). Performance of a
stochastic learning microchip.  In D. S. Touretzky (ed.), {\it
  Advances in Neural Information Processing Systems 1}, 748-760.  San
Mateo, Calif.: Morgan Kaufmann.

F.~Rosenblatt (1962). {\it Principles of Neurodynamics.} Washington,
D.C.: Spartan Books.

G.~Tesauro (1989). Neurogammon wins computer Olympiad.  {\it Neural
  Computation} {\bf 1}(3):321-323.

\end{document}

